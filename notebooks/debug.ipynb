{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents DB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-05 01:22:43 - INFO - Reading file '../data/raw/fintech-scopus.csv' ...\n",
      "2021-11-05 01:22:44 - INFO - 1301 raw records found.\n",
      "2021-11-05 01:22:44 - INFO - Deleting/renaming columns ...\n",
      "2021-11-05 01:22:44 - INFO - Removing accents ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1122: expected 50 fields, saw 51\\nSkipping line 1123: expected 50 fields, saw 51\\nSkipping line 1124: expected 50 fields, saw 51\\nSkipping line 1125: expected 50 fields, saw 51\\nSkipping line 1126: expected 50 fields, saw 51\\nSkipping line 1127: expected 50 fields, saw 51\\nSkipping line 1128: expected 50 fields, saw 51\\nSkipping line 1129: expected 50 fields, saw 51\\nSkipping line 1130: expected 50 fields, saw 51\\nSkipping line 1131: expected 50 fields, saw 51\\nSkipping line 1132: expected 50 fields, saw 51\\nSkipping line 1133: expected 50 fields, saw 51\\nSkipping line 1134: expected 50 fields, saw 51\\nSkipping line 1135: expected 50 fields, saw 51\\nSkipping line 1136: expected 50 fields, saw 51\\nSkipping line 1137: expected 50 fields, saw 51\\nSkipping line 1138: expected 50 fields, saw 51\\nSkipping line 1139: expected 50 fields, saw 51\\nSkipping line 1140: expected 50 fields, saw 51\\nSkipping line 1141: expected 50 fields, saw 51\\nSkipping line 1142: expected 50 fields, saw 51\\nSkipping line 1143: expected 50 fields, saw 51\\nSkipping line 1144: expected 50 fields, saw 51\\nSkipping line 1145: expected 50 fields, saw 51\\nSkipping line 1146: expected 50 fields, saw 51\\nSkipping line 1147: expected 50 fields, saw 51\\nSkipping line 1148: expected 50 fields, saw 51\\nSkipping line 1149: expected 50 fields, saw 51\\nSkipping line 1150: expected 50 fields, saw 51\\nSkipping line 1151: expected 50 fields, saw 51\\nSkipping line 1152: expected 50 fields, saw 51\\nSkipping line 1153: expected 50 fields, saw 51\\nSkipping line 1154: expected 50 fields, saw 51\\nSkipping line 1155: expected 50 fields, saw 51\\nSkipping line 1156: expected 50 fields, saw 51\\nSkipping line 1157: expected 50 fields, saw 51\\nSkipping line 1158: expected 50 fields, saw 51\\nSkipping line 1159: expected 50 fields, saw 51\\nSkipping line 1160: expected 50 fields, saw 51\\nSkipping line 1161: expected 50 fields, saw 51\\nSkipping line 1162: expected 50 fields, saw 51\\nSkipping line 1163: expected 50 fields, saw 51\\nSkipping line 1164: expected 50 fields, saw 51\\nSkipping line 1165: expected 50 fields, saw 51\\nSkipping line 1166: expected 50 fields, saw 51\\nSkipping line 1167: expected 50 fields, saw 51\\nSkipping line 1168: expected 50 fields, saw 51\\nSkipping line 1169: expected 50 fields, saw 51\\nSkipping line 1170: expected 50 fields, saw 51\\nSkipping line 1171: expected 50 fields, saw 51\\nSkipping line 1172: expected 50 fields, saw 51\\nSkipping line 1173: expected 50 fields, saw 51\\nSkipping line 1174: expected 50 fields, saw 51\\nSkipping line 1175: expected 50 fields, saw 51\\nSkipping line 1176: expected 50 fields, saw 51\\nSkipping line 1177: expected 50 fields, saw 51\\nSkipping line 1178: expected 50 fields, saw 51\\nSkipping line 1179: expected 50 fields, saw 51\\nSkipping line 1180: expected 50 fields, saw 51\\nSkipping line 1181: expected 50 fields, saw 51\\nSkipping line 1182: expected 50 fields, saw 51\\nSkipping line 1183: expected 50 fields, saw 51\\nSkipping line 1184: expected 50 fields, saw 51\\nSkipping line 1185: expected 50 fields, saw 51\\nSkipping line 1186: expected 50 fields, saw 51\\nSkipping line 1187: expected 50 fields, saw 51\\nSkipping line 1188: expected 50 fields, saw 51\\nSkipping line 1189: expected 50 fields, saw 51\\nSkipping line 1190: expected 50 fields, saw 51\\nSkipping line 1191: expected 50 fields, saw 51\\nSkipping line 1192: expected 50 fields, saw 51\\nSkipping line 1193: expected 50 fields, saw 51\\nSkipping line 1194: expected 50 fields, saw 51\\nSkipping line 1195: expected 50 fields, saw 51\\nSkipping line 1196: expected 50 fields, saw 51\\nSkipping line 1197: expected 50 fields, saw 51\\nSkipping line 1198: expected 50 fields, saw 51\\nSkipping line 1199: expected 50 fields, saw 51\\nSkipping line 1200: expected 50 fields, saw 51\\nSkipping line 1201: expected 50 fields, saw 51\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-05 01:22:44 - INFO - Processing abstracts ...\n",
      "2021-11-05 01:22:44 - INFO - Processing affiliations ...\n",
      "2021-11-05 01:22:47 - INFO - Processing author keywords ...\n",
      "2021-11-05 01:22:47 - INFO - Processing authors_id ...\n",
      "2021-11-05 01:22:47 - INFO - Formating raw authors names ...\n",
      "2021-11-05 01:22:47 - INFO - Dropping duplicates ...\n",
      "2021-11-05 01:22:47 - INFO - Duplicate rows found in ../data/processed/debug/documents.csv - Records saved to {filename}\n",
      "2021-11-05 01:22:47 - INFO - Searching local references using DOI ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1301/1301 [00:16<00:00, 78.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-05 01:23:04 - INFO - Searching local references using document titles ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1301/1301 [00:18<00:00, 68.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-05 01:23:23 - INFO - Consolidating local references ...\n",
      "2021-11-05 01:23:23 - INFO - Computing local citations ...\n",
      "2021-11-05 01:23:23 - INFO - Computing Bradford Law Zones ...\n",
      "2021-11-05 01:23:24 - INFO - Documents saved/merged to '../data/processed/debug/documents.csv'\n",
      "2021-11-05 01:23:24 - INFO - Post-processing docuemnts ...\n",
      "2021-11-05 01:23:24 - INFO - Creating institutions thesaurus ...\n",
      "2021-11-05 01:23:25 - INFO - Affiliations without country detected - check file ../data/processed/debug/ignored_affiliations.txt\n",
      "2021-11-05 01:23:25 - INFO - Affiliations without country detected - check file ../data/processed/debug/ignored_affiliations.txt\n",
      "2021-11-05 01:23:25 - INFO - Thesaurus file '../data/processed/debug/institutions.txt' created.\n",
      "2021-11-05 01:23:25 - INFO - Creating keywords thesaurus ...\n",
      "2021-11-05 01:23:28 - INFO - Thesaurus file '../data/processed/debug/keywords.txt' created.\n",
      "2021-11-05 01:23:28 - INFO - Applying thesaurus to institutions ...\n",
      "2021-11-05 01:23:28 - INFO - Extract and cleaning institutions.\n",
      "2021-11-05 01:23:28 - INFO - Extracting institution of first author ...\n",
      "2021-11-05 01:23:29 - INFO - The thesaurus was applied to institutions.\n",
      "2021-11-05 01:23:29 - INFO - Applying thesaurus to keywords ...\n",
      "2021-11-05 01:23:31 - INFO - The thesaurus was applied to keywords.\n",
      "2021-11-05 01:23:31 - INFO - Process finished!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from techminer import *\n",
    "\n",
    "directory = \"../data/processed/debug\"\n",
    "file_name = \"../data/raw/fintech-scopus.csv\"\n",
    "import_scopus_file_to_directory(file_name, directory)\n",
    "\n",
    "# !cat ../data/processed/debug/filter.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from techminer import *\n",
    "\n",
    "# clean_institution_fields(dirpath=\"../data/processed/debug\")\n",
    "# clean_keywords_fields(dirpath=\"../data/processed/debug\")\n",
    "\n",
    "# apply_thesaurus(dirpath_or_records=\"../data/processed/debug\", thesaurus_filepath=\"../data/processed/debug/keywords.txt\", input_column=\"author_keywords\", output_column=\"author_keywords_thesaurus\")\n",
    "# create_thesaurus(dirpath_or_records=\"../data/processed/debug\", column=\"keywords\", thesaurus_filepath=\"../data/processed/debug/test_thesaurus.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from techminer import *\n",
    "\n",
    "# bradford_plot(dirpath_or_records=\"../data/processed/debug\")\n",
    "# core_authors(dirpath_or_records=\"../data/processed/debug\")\n",
    "# core_sources(dirpath_or_records=\"../data/processed/debug\")\n",
    "# coverage(dirpath_or_records=\"../data/processed/debug\")\n",
    "# lotka_plot(dirpath_or_records=\"../data/processed/debug\")\n",
    "# summary(dirpath_or_records=\"../data/processed/debug\")\n",
    "# most_cited_documents(dirpath_or_records=\"../data/processed/debug\")\n",
    "# terms_table(dirpath_or_records=\"../data/processed/debug\", column='authors')\n",
    "# worldmap(dirpath_or_records=\"../data/processed/debug\", metric='num_records')\n",
    "# time_table(dirpath_or_records=\"../data/processed/debug\")\n",
    "\n",
    "# terms_per_year_table(dirpath_or_records=\"../data/processed/debug\", column='countries')\n",
    "\n",
    "# TermAnalyzer(dirpath_or_records=\"../data/processed/debug\", column='countries', top_by='num_records').table_\n",
    "# TimeAnalyzer(dirpath_or_records=\"../data/processed/debug\").barh(column='num_documents', cmap=\"Blues\")\n",
    "# worldmap(count_records_by_term(dirpath_or_records=\"../data/processed/debug\", column=\"countries\"))\n",
    "\n",
    "\n",
    "# BigraphAnalyzer(dirpath_or_records=\"../data/processed/debug\", column='countries', by='countries').table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply_thesaurus(directory_or_records=\"../data/processed/debug\", thesaurus_filepath=\"../data/processed/debug/keywords.txt\", input_column=\"author_keywords\", output_column=\"author_keywords_thesaurus\")\n",
    "# association_index(co_occurrence_matrix(directory_or_records=\"../data/processed/debug\", column=\"author_keywords\"), association='jaccard')\n",
    "\n",
    "# co_occurrence_matrix(directory_or_records=\"../data/processed/debug\", column=\"author_keywords\", by='author_keywords')\n",
    "# co_occurrence_matrix(directory_or_records=\"../data/processed/debug\", column=\"author_keywords\", by='countries')\n",
    "\n",
    "\n",
    "\n",
    "# create_thesaurus(directory_or_records=\"../data/processed/debug\", column=\"keywords\", thesaurus_filepath=\"../data/processed/debug/test_thesaurus.txt\")\n",
    "# impact_analysis(directory_or_records=\"../data/processed/debug\", column=\"authors\")\n",
    "# tf_matrix(directory_or_records=\"../data/processed/debug\", column=\"author_keywords\")\n",
    "# tfidf_matrix(tf_matrix(directory_or_records=\"../data/processed/debug\", column=\"author_keywords\"))\n",
    "\n",
    "# collaboration_analysis(directory_or_records=\"../data/processed/debug\", column=\"authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"../data/processed/debug/documents.csv\").iso_source_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data/processed/debug/documents.csv\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
