{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'karateclub', 'leidenalg', 'infomap', 'wurlitzer', 'graph_tool'}\n",
      "Note: to be able to use all overlapping methods, you need to install some additional packages:  {'karateclub', 'ASLPAw'}\n",
      "Note: to be able to use all bipartite methods, you need to install some additional packages:  {'wurlitzer', 'infomap', 'leidenalg'}\n",
      "--INFO-- Creating `words.txt` from author/index keywords, and abstract/title words\n",
      "--INFO-- Applying `words.txt` thesaurus to author/index keywords and abstract/title words\n",
      "--INFO-- The regtech/processed/countries.txt thesaurus file was created\n",
      "--INFO-- The regtech/processed/countries.txt thesaurus file was applied to affiliations in all databases\n",
      "--INFO-- The regtech/processed/institutions.txt thesaurus file was created\n",
      "--INFO-- The regtech/processed/institutions.txt thesaurus file was applied to affiliations in all databases\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "# --- \n",
    "from techminer2 import *\n",
    "\n",
    "directory = \"regtech\"\n",
    "\n",
    "import_scopus_files(directory)\n",
    "# import_references()\n",
    "# annual_scientific_production()\n",
    "# main_information(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"regtech\"\n",
    "\n",
    "documents = pd.read_csv(f\"{directory}/processed/_documents.csv\")\n",
    "references = pd.read_csv(f\"{directory}/processed/_references.csv\")\n",
    "\n",
    "documents.article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_references = documents.global_references.copy()\n",
    "cited_references = cited_references.str.lower()\n",
    "cited_references = cited_references.str.split(\";\")\n",
    "cited_references = cited_references.explode()\n",
    "cited_references = cited_references.str.strip()\n",
    "cited_references = cited_references.dropna()\n",
    "cited_references = cited_references.drop_duplicates()\n",
    "cited_references = cited_references.reset_index(drop=True)\n",
    "\n",
    "thesaurus = {t: None for t in cited_references.tolist()}\n",
    "\n",
    "references['found'] = False\n",
    "\n",
    "\n",
    "#\n",
    "# Busqueda por DOI\n",
    "#\n",
    "for doi, article in zip(references.doi, references.article):\n",
    "    for key in thesaurus.keys():\n",
    "        if not pd.isna(doi) and doi in key:\n",
    "            thesaurus[key] = article\n",
    "            references.found[references.doi == doi] = True\n",
    "\n",
    "#\n",
    "# Reduce la base de búsqueda\n",
    "#\n",
    "references = references[references.found == False]\n",
    "\n",
    "#\n",
    "# Busqueda por año, autor y tttulo\n",
    "#\n",
    "for article, year, authors, title in zip(\n",
    "    references.article, \n",
    "    references.year,\n",
    "    references.authors,\n",
    "    references.title,\n",
    "):\n",
    "    year = str(year)\n",
    "    author = authors.split()[0].lower()\n",
    "    title = title.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\";\", \"\").replace(\"-\", \" \").replace(\"'\", \"\")\n",
    "    \n",
    "    for key in thesaurus.keys():\n",
    "        text = key\n",
    "        text = text.lower()\n",
    "        text = text.replace(\".\", \"\")\n",
    "        text = text.replace(\",\", \"\")\n",
    "        text = text.replace(\":\", \"\")\n",
    "        text = text.replace(\";\", \"\")\n",
    "        text = text.replace(\"-\", \" \")\n",
    "        text = text.replace(\"'\", \"\")\n",
    "\n",
    "        if (\n",
    "            author in text and \n",
    "            str(year) in text and \n",
    "            title[:29] in text\n",
    "        ):\n",
    "            thesaurus[key] = article\n",
    "            references.found[references.article == article] = True\n",
    "        elif (\n",
    "            author in text and \n",
    "            str(year) in text and \n",
    "            title[-29:] in text\n",
    "        ):\n",
    "            thesaurus[key] = article\n",
    "            references.found[references.article == article] = True\n",
    "\n",
    "\n",
    "#\n",
    "# Reduce la base de búsqueda\n",
    "#\n",
    "references = references[references.found == False]\n",
    "\n",
    "#\n",
    "# Busqueda por titulo\n",
    "#\n",
    "for article, title in zip(\n",
    "    references.article, \n",
    "    references.title,\n",
    "):\n",
    "    \n",
    "    \n",
    "    title = title.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\")\n",
    "    \n",
    "    for key in thesaurus.keys():\n",
    "        text = key\n",
    "        text = text.lower()\n",
    "        text = text.replace(\".\", \"\")\n",
    "        text = text.replace(\",\", \"\")\n",
    "        text = text.replace(\":\", \"\")\n",
    "\n",
    "        if (            \n",
    "            title in text\n",
    "        ):\n",
    "            thesaurus[key] = article\n",
    "            references.found[references.article == article] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"report.txt\", \"w\") as f:\n",
    "    for key, value in thesaurus.items():\n",
    "        if value is None:\n",
    "            f.write(f\"{key}\\n\")\n",
    "    \n",
    "    f.write(\"\\n-----------------------\\n\\n\")\n",
    "\n",
    "    for article, found, title in zip(\n",
    "        references.article, \n",
    "        references.found,\n",
    "        references.title,\n",
    "        \n",
    "    ):\n",
    "        if found is False:\n",
    "            f.write(f\"{article} --- {title}\\n\")\n",
    "\n",
    "for key in thesaurus.keys():\n",
    "    if thesaurus[key] is not None:\n",
    "        print(thesaurus[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "     ... \n",
       "89    NaN\n",
       "90    NaN\n",
       "91    NaN\n",
       "92    NaN\n",
       "93    NaN\n",
       "Name: local_references, Length: 94, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"regtech\"\n",
    "pd.read_csv(f\"{directory}/processed/_documents.csv\").local_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create__local_citations__column_in_documents_database(directory):\n",
    "\n",
    "    # sys.stdout.write(\n",
    "    #     \"--INFO-- Creating `local_citations` column in references database\\n\"\n",
    "    # )\n",
    "\n",
    "    # counts the number of citations for each local reference\n",
    "    documents_path = os.path.join(directory, \"processed\", \"_documents.csv\")\n",
    "    documents = pd.read_csv(documents_path)\n",
    "    local_references = documents.local_references.copy()\n",
    "    local_references = local_references.dropna()\n",
    "    local_references = local_references.str.split(\";\")\n",
    "    local_references = local_references.explode()\n",
    "    local_references = local_references.str.strip()\n",
    "    local_references = local_references.value_counts()\n",
    "    values_dict = local_references.to_dict()\n",
    "\n",
    "    # assigns the number of citations to each reference in references database\n",
    "    documents[\"local_citations\"] = documents.article\n",
    "    documents[\"local_citations\"] = documents[\"local_citations\"].map(values_dict)\n",
    "    documents[\"local_citations\"] = documents[\"local_citations\"].fillna(0)\n",
    "\n",
    "    # saves the new column in the references database\n",
    "    documents.to_csv(documents_path, index=False)\n",
    "\n",
    "directory = \"regtech\"\n",
    "_create__local_citations__column_in_documents_database(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff8a4715c70c0e4b3cc8412ea892d5df3eeb381ac1fbe083ff6ed76fad7df612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
