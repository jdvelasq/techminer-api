{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bop\n",
      "     base of pyramid (bop)\n",
      "     bop consumers\n",
      "     bop contexts\n",
      "     bop entrepreneurs\n",
      "     bop entrepreneurship\n",
      "     bop inhabitants\n",
      "language\n",
      "     computer language python\n",
      "     english (language)\n",
      "     english language\n",
      "     natural language processing\n",
      "micro-operating mechanism\n",
      "     mom(micro-operating mechanism)\n",
      "smes\n",
      "     fintech smes\n",
      "     indian fintech smes\n",
      "     small and medium-sized enterprises (smes)\n",
      "     soe smes\n",
      "sri\n",
      "     socially responsible investing (sri)\n",
      "     sri lanka\n",
      "soes\n",
      "     state-owned enterprises (soes)\n",
      "utaut\n",
      "     unified theory of acceptance and use technology (utaut)\n",
      "     utaut\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "from os.path import isfile, join\n",
    "from techminer2.thesaurus import load_file_as_dict\n",
    "\n",
    "\n",
    "from techminer2 import *\n",
    "\n",
    "directory = \"/workspaces/techminer2/data/\"\n",
    "\n",
    "def find_abbreviations(\n",
    "    directory=\"./\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Find abbreviations and reorder the thesaurus to reflect the search.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_abbreviation(x):\n",
    "        if \"(\" in x:\n",
    "            abbreviation = x[x.find(\"(\") + 1 : x.find(\")\")]\n",
    "            return abbreviation\n",
    "        return None\n",
    "\n",
    "    # ----< Load and reverse the thesaurus >------------------------------------------------------\n",
    "    thesaurus_file = join(directory, \"keywords.txt\")\n",
    "    if isfile(thesaurus_file):\n",
    "        th = load_file_as_dict(thesaurus_file)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"The file {} does not exist.\".format(thesaurus_file))\n",
    "    reversed_th = {value: key for key, values in th.items() for value in values}\n",
    "\n",
    "    # ----< search for abbreviations >-------------------------------------------------------------\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": reversed_th.keys(),\n",
    "            \"key\": reversed_th.values(),\n",
    "        }\n",
    "    )\n",
    "    df[\"abbreviation\"] = df[\"key\"].map(extract_abbreviation)\n",
    "\n",
    "    # ----< filter by each abbreviation >----------------------------------------------------------\n",
    "    abbreviations = df.abbreviation.dropna().drop_duplicates()\n",
    "    results = {}\n",
    "    for abbreviation in abbreviations.to_list():\n",
    "        keywords = df[df.text.str.contains(abbreviation)]\n",
    "        if len(keywords) > 0:\n",
    "            \n",
    "            results[abbreviation] = keywords\n",
    "\n",
    "            print(abbreviation)\n",
    "            for text in keywords.text.to_list():\n",
    "                print(\"    \", text)\n",
    "\n",
    "    #Â ----< remove found keywords >-----------------------------------------------------------------\n",
    "    keys = [text  for key in results.keys() for text in results[key].key.to_list()]\n",
    "    findings = {key: th[key] for key in sorted(keys)}\n",
    "    for key in findings.keys():\n",
    "        th.pop(key)\n",
    "\n",
    "    with open(thesaurus_file + '_', \"w\", encoding=\"utf-8\") as file:\n",
    "\n",
    "        for key in sorted(findings.keys()):\n",
    "            file.write(key + \"\\n\")\n",
    "            for item in findings[key]:\n",
    "                file.write(\"    \" + item + \"\\n\")\n",
    "\n",
    "        for key in sorted(th.keys()):\n",
    "            file.write(key + \"\\n\")\n",
    "            for item in th[key]:\n",
    "                file.write(\"    \" + item + \"\\n\")\n",
    "\n",
    "\n",
    "find_abbreviations(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_keywords(directory)\n",
    "thematic_map_communities('author_keywords', min_occ=10, directory=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_global_cited_documents(directory=directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nlp = pd.read_csv(\"/workspaces/techminer2/data/documents.csv\").nlp_phrases\n",
    "nlp = nlp.str.split(\";\")\n",
    "nlp = nlp.explode()\n",
    "nlp = nlp.str.strip()\n",
    "nlp = nlp.str.lower()\n",
    "nlp = nlp.dropna()\n",
    "nlp = nlp.drop_duplicates()\n",
    "nlp = nlp.sort_values()\n",
    "nlp = nlp.reset_index(drop=True)\n",
    "nlp.to_csv(\"nlp.txt\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /workspaces/techminer2/data/raw-documents.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.raw_author_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from techminer import *\n",
    "directory = \"/workspaces/techminer-api/data/\"\n",
    "collaboration_indicators(\"countries\", directory=directory).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.DataFrame(\n",
    "    {\n",
    "    'a': [1, 1, 1, 2, 2, 2],\n",
    "    'b': ['A', 'B', 'D', 'A', 'B', 'C'],\n",
    "    'v': [1, 2, 3, 4, 5, 6]\n",
    "    }\n",
    ")\n",
    "m.pivot(index='a', columns='b', values='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sorted(pd.read_csv(\"documents.csv\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
