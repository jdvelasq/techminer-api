{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  2020, springer nature limited'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "# --- \n",
    "from techminer2 import *\n",
    "import pandas as pd\n",
    "directory = \"regtech\"\n",
    "\n",
    "# import_scopus_files(directory)\n",
    "# import_references()\n",
    "# annual_scientific_production()\n",
    "# main_information(directory)\n",
    "\n",
    "with open(os.path.join(directory, \"processed/_documents.csv\"), \"r\") as f:\n",
    "    documents = pd.read_csv(f)\n",
    "    abstracts = documents[\"abstract\"]\n",
    "    abstracts = abstracts.dropna()\n",
    "    abstracts = abstracts.str.split(\".\")\n",
    "    abstracts = abstracts.map(lambda x: [y for y in x if y != \"\"])\n",
    "    abstracts = abstracts.str[-1]\n",
    "abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"regtech\"\n",
    "pd.read_csv(f\"{directory}/processed/_documents.csv\").local_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "\n",
    "def _extract_keywords_from_database_files(directory):\n",
    "    keywords_list = []\n",
    "    files = list(glob.glob(os.path.join(directory, \"processed/_*.csv\")))\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        if \"raw_index_keywords\" in data.columns:\n",
    "            keywords_list += data.raw_index_keywords.dropna().tolist()\n",
    "        if \"raw_author_keywords\" in data.columns:\n",
    "            keywords_list += data.raw_author_keywords.dropna().tolist()\n",
    "    keywords_list = pd.DataFrame({\"keyword\": keywords_list})\n",
    "    keywords_list = keywords_list.assign(keyword=keywords_list.keyword.str.split(\";\"))\n",
    "    keywords_list = keywords_list.explode(\"keyword\")\n",
    "    keywords_list = keywords_list.keyword.str.strip()\n",
    "    keywords_list = keywords_list.drop_duplicates()\n",
    "    keywords_list = keywords_list.reset_index(drop=True)\n",
    "    return keywords_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "def _extract_keywords_roots_from_database_files(directory):\n",
    "    \n",
    "    keywords_list = []\n",
    "    \n",
    "    files = list(glob.glob(os.path.join(directory, \"processed/_*.csv\")))\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        for column in [\"raw_author_keywords\", \"raw_index_keywords\"]:\n",
    "            keywords_list.append(data[column])\n",
    "\n",
    "    keywords_list = pd.concat(keywords_list)\n",
    "    keywords_list = keywords_list.dropna()\n",
    "    keywords_list = keywords_list.str.split(\";\")\n",
    "    keywords_list = keywords_list.explode()\n",
    "    keywords_list = keywords_list.str.strip()\n",
    "    keywords_list = keywords_list.drop_duplicates()\n",
    "\n",
    "    keywords_list = keywords_list.str.replace(r\"\\[.+\\]\", \"\", regex=True)\n",
    "    keywords_list = keywords_list.str.replace(r\"\\(.+\\)\", \"\", regex=True)\n",
    "    keywords_list = keywords_list.str.replace(r\"-\", \" \", regex=False)\n",
    "    keywords_list = keywords_list.str.replace(r\"&\", \" \", regex=False)\n",
    "\n",
    "    # list of single words\n",
    "    keywords_list = keywords_list.str.split()\n",
    "    s = PorterStemmer()\n",
    "    keywords_list = keywords_list.map(lambda x: [s.stem(y) for y in x])\n",
    "    keywords_list = keywords_list.map(set)\n",
    "    keywords_list = keywords_list.map(sorted)\n",
    "    keywords_list = keywords_list.map(lambda x: \" \".join(x))\n",
    "\n",
    "    return keywords_list\n",
    "\n",
    "\n",
    "def _create__raw_words__column(directory, source_column, dest_column):\n",
    "\n",
    "    #\n",
    "    roots = _extract_keywords_roots_from_database_files(directory).to_list()\n",
    "    \n",
    "    #\n",
    "    files = list(glob.glob(os.path.join(directory, \"processed/_*.csv\")))\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        #\n",
    "        if source_column not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sys.stdout.write(f\"--INFO-- Creating `{dest_column}` column in {file}\\n\")\n",
    "\n",
    "        text = data[['article', source_column]].copy()\n",
    "        text = text.dropna()\n",
    "        \n",
    "        text[source_column] = text[source_column].str.lower().copy()\n",
    "        \n",
    "        \n",
    "        text['raw_words'] = text[source_column].map(lambda x: TextBlob(x).noun_phrases)\n",
    "        text = text.explode('raw_words')\n",
    "        text = text.dropna()\n",
    "        text['keys'] = text['raw_words'].str.split()\n",
    "        s = PorterStemmer()\n",
    "        text['keys'] = text['keys'].map(lambda x: [s.stem(y) for y in x])\n",
    "        text['keys'] = text['keys'].map(set)\n",
    "        text['keys'] = text['keys'].map(sorted)\n",
    "        text['keys'] = text['keys'].map(lambda x: \" \".join(x))\n",
    "        \n",
    "        text['found'] = text['keys'].map(lambda x: x in roots)\n",
    "        text = text[text['found'] == True]\n",
    "\n",
    "        text = text[['article', 'raw_words']]\n",
    "        text = text.groupby('article', as_index=False).aggregate(lambda x: list(x))\n",
    "        text['raw_words'] = text['raw_words'].map(set)\n",
    "        text['raw_words'] = text['raw_words'].map(sorted)\n",
    "        text['raw_words'] = text['raw_words'].str.join(\"; \")\n",
    "\n",
    "        # convert the pandas series to a dictionary\n",
    "        values_dict = dict(zip(text.article, text.raw_words))\n",
    "        data[dest_column] = data['article'].map(lambda x: values_dict.get(x, pd.NA))\n",
    "        #\n",
    "        data.to_csv(file, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "directory = \"regtech\"\n",
    "_create__raw_abstract_words__column(directory, source_column='abstract', dest_column='raw_abstract_words')\n",
    "_create__raw_abstract_words__column(directory, source_column='title', dest_column='raw_title_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"regtech\"\n",
    "\n",
    "documents = pd.read_csv(f\"{directory}/processed/_documents.csv\")\n",
    "\n",
    "index=2\n",
    "print(documents.raw_abstract_words[index])\n",
    "print(documents.raw_title_words[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents.raw_author_keywords[index])\n",
    "print(documents.raw_index_keywords[index])\n",
    "print(documents.title[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents.raw_index_keywords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff8a4715c70c0e4b3cc8412ea892d5df3eeb381ac1fbe083ff6ed76fad7df612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
