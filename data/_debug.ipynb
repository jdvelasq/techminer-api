{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--INFO-- Concatenating raw files in mateo/raw/cited_by/\n",
      "--INFO-- Concatenating raw files in mateo/raw/references/\n",
      "--INFO-- Concatenating raw files in mateo/raw/documents/\n",
      "--INFO-- Applying scopus tags to database files\n",
      "--INFO-- Formating column names in database files\n",
      "--INFO-- Dropping NA columns in database files\n",
      "--INFO-- Removing accents in database files\n",
      "--INFO-- Removing stranger chars in database files\n",
      "--INFO-- Processing `abstract` column\n",
      "--INFO-- Processing `authors_id` column\n",
      "--INFO-- Processing `title` column\n",
      "--INFO-- Processing `document_type` column\n",
      "--INFO-- Processing `doi` column\n",
      "--INFO-- Processing `eissn` column\n",
      "--INFO-- Processing `global_citations` column\n",
      "--INFO-- Processing `isbn` column\n",
      "--INFO-- Processing `issn` column\n",
      "--INFO-- Processing `raw_authors` column\n",
      "--INFO-- Processing `source_abbr` column\n",
      "--INFO-- Processing `source_name` column\n",
      "--INFO-- Processing `global_references` column\n",
      "--INFO-- Creating `authors` column\n",
      "--INFO-- Creating `num_authors` column\n",
      "--INFO-- Creating `article` column\n",
      "--INFO-- Processing `raw_author_keywords` column\n",
      "--INFO-- Processing `raw_index_keywords` column\n",
      "--INFO-- Creating `raw_abstract_words` column in mateo/processed/_documents.csv\n",
      "--INFO-- Creating `raw_title_words` column in mateo/processed/_documents.csv\n",
      "--INFO-- Creating `raw_title_words` column in mateo/processed/_references.csv\n",
      "--INFO-- Creating `raw_title_words` column in mateo/processed/_cited_by.csv\n",
      "--INFO-- Creating `raw_words` column\n",
      "--INFO-- Creating `keywords.txt` from author/index keywords, and abstract/title words\n",
      "--INFO-- Applying `keywords.txt` thesaurus to author/index keywords and abstract/title words\n",
      "--INFO-- The mateo/processed/countries.txt thesaurus file was created\n",
      "--INFO-- The mateo/processed/countries.txt thesaurus file was applied to affiliations in all databases\n",
      "--INFO-- Creating `num_global_references` column\n",
      "--INFO-- Complete `source_abbr` column\n",
      "--INFO-- Creating `abstract.csv` file from `documents` database\n",
      "--INFO-- Creating `bradford` column\n",
      "--INFO-- Searching `references` using DOI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73830/73830 [1:41:38<00:00, 12.11it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--INFO-- Searching `references` using (year, title, author)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 71563/71613 [4:44:35<00:11,  4.19it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--INFO-- Searching `references` using (title)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7801/7801 [34:26<00:00,  3.77it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--INFO-- Creating `local_citations` column in references database\n",
      "--INFO-- Creating `local_citations` column in documents database\n",
      "--INFO-- The mateo/processed/organizations.txt thesaurus file was created\n",
      "--INFO-- The mateo/processed/organizations.txt thesaurus file was applied to affiliations in all databases\n",
      "--INFO-- Process finished!!!\n",
      "--INFO-- mateo/processed/_documents.csv: 3859 imported records\n",
      "--INFO-- mateo/processed/_references.csv: 73830 imported records\n",
      "--INFO-- mateo/processed/_cited_by.csv: 22220 imported records\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "\n",
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "# --- \n",
    "from techminer2 import *\n",
    "import pandas as pd\n",
    "directory = \"mateo\"\n",
    "\n",
    "tm2__import_scopus_files(directory)\n",
    "# import_references()\n",
    "# annual_scientific_production()\n",
    "# main_information(directory)\n",
    "\n",
    "# with open(os.path.join(directory, \"processed/_documents.csv\"), \"r\") as f:\n",
    "#     documents = pd.read_csv(f)\n",
    "#     abstracts = documents[\"abstract\"]\n",
    "#     abstracts = abstracts.dropna()\n",
    "#     abstracts = abstracts.str.split(\".\")\n",
    "#     abstracts = abstracts.map(lambda x: [y for y in x if y != \"\"])\n",
    "#     abstracts = abstracts.str[-1]\n",
    "# abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"regtech\"\n",
    "pd.read_csv(f\"{directory}/processed/_documents.csv\").local_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "\n",
    "def _extract_keywords_from_database_files(directory):\n",
    "    keywords_list = []\n",
    "    files = list(glob.glob(os.path.join(directory, \"processed/_*.csv\")))\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        if \"raw_index_keywords\" in data.columns:\n",
    "            keywords_list += data.raw_index_keywords.dropna().tolist()\n",
    "        if \"raw_author_keywords\" in data.columns:\n",
    "            keywords_list += data.raw_author_keywords.dropna().tolist()\n",
    "    keywords_list = pd.DataFrame({\"keyword\": keywords_list})\n",
    "    keywords_list = keywords_list.assign(keyword=keywords_list.keyword.str.split(\";\"))\n",
    "    keywords_list = keywords_list.explode(\"keyword\")\n",
    "    keywords_list = keywords_list.keyword.str.strip()\n",
    "    keywords_list = keywords_list.drop_duplicates()\n",
    "    keywords_list = keywords_list.reset_index(drop=True)\n",
    "    return keywords_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "def _extract_keywords_roots_from_database_files(directory):\n",
    "    \n",
    "    keywords_list = []\n",
    "    \n",
    "    files = list(glob.glob(os.path.join(directory, \"processed/_*.csv\")))\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        for column in [\"raw_author_keywords\", \"raw_index_keywords\"]:\n",
    "            keywords_list.append(data[column])\n",
    "\n",
    "    keywords_list = pd.concat(keywords_list)\n",
    "    keywords_list = keywords_list.dropna()\n",
    "    keywords_list = keywords_list.str.split(\";\")\n",
    "    keywords_list = keywords_list.explode()\n",
    "    keywords_list = keywords_list.str.strip()\n",
    "    keywords_list = keywords_list.drop_duplicates()\n",
    "\n",
    "    keywords_list = keywords_list.str.replace(r\"\\[.+\\]\", \"\", regex=True)\n",
    "    keywords_list = keywords_list.str.replace(r\"\\(.+\\)\", \"\", regex=True)\n",
    "    keywords_list = keywords_list.str.replace(r\"-\", \" \", regex=False)\n",
    "    keywords_list = keywords_list.str.replace(r\"&\", \" \", regex=False)\n",
    "\n",
    "    # list of single words\n",
    "    keywords_list = keywords_list.str.split()\n",
    "    s = PorterStemmer()\n",
    "    keywords_list = keywords_list.map(lambda x: [s.stem(y) for y in x])\n",
    "    keywords_list = keywords_list.map(set)\n",
    "    keywords_list = keywords_list.map(sorted)\n",
    "    keywords_list = keywords_list.map(lambda x: \" \".join(x))\n",
    "\n",
    "    return keywords_list\n",
    "\n",
    "\n",
    "def _create__raw_words__column(directory, source_column, dest_column):\n",
    "\n",
    "    #\n",
    "    roots = _extract_keywords_roots_from_database_files(directory).to_list()\n",
    "    \n",
    "    #\n",
    "    files = list(glob.glob(os.path.join(directory, \"processed/_*.csv\")))\n",
    "    for file in files:\n",
    "        data = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        #\n",
    "        if source_column not in data.columns:\n",
    "            continue\n",
    "\n",
    "        sys.stdout.write(f\"--INFO-- Creating `{dest_column}` column in {file}\\n\")\n",
    "\n",
    "        text = data[['article', source_column]].copy()\n",
    "        text = text.dropna()\n",
    "        \n",
    "        text[source_column] = text[source_column].str.lower().copy()\n",
    "        \n",
    "        \n",
    "        text['raw_words'] = text[source_column].map(lambda x: TextBlob(x).noun_phrases)\n",
    "        text = text.explode('raw_words')\n",
    "        text = text.dropna()\n",
    "        text['keys'] = text['raw_words'].str.split()\n",
    "        s = PorterStemmer()\n",
    "        text['keys'] = text['keys'].map(lambda x: [s.stem(y) for y in x])\n",
    "        text['keys'] = text['keys'].map(set)\n",
    "        text['keys'] = text['keys'].map(sorted)\n",
    "        text['keys'] = text['keys'].map(lambda x: \" \".join(x))\n",
    "        \n",
    "        text['found'] = text['keys'].map(lambda x: x in roots)\n",
    "        text = text[text['found'] == True]\n",
    "\n",
    "        text = text[['article', 'raw_words']]\n",
    "        text = text.groupby('article', as_index=False).aggregate(lambda x: list(x))\n",
    "        text['raw_words'] = text['raw_words'].map(set)\n",
    "        text['raw_words'] = text['raw_words'].map(sorted)\n",
    "        text['raw_words'] = text['raw_words'].str.join(\"; \")\n",
    "\n",
    "        # convert the pandas series to a dictionary\n",
    "        values_dict = dict(zip(text.article, text.raw_words))\n",
    "        data[dest_column] = data['article'].map(lambda x: values_dict.get(x, pd.NA))\n",
    "        #\n",
    "        data.to_csv(file, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "directory = \"regtech\"\n",
    "_create__raw_abstract_words__column(directory, source_column='abstract', dest_column='raw_abstract_words')\n",
    "_create__raw_abstract_words__column(directory, source_column='title', dest_column='raw_title_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"regtech\"\n",
    "\n",
    "documents = pd.read_csv(f\"{directory}/processed/_documents.csv\")\n",
    "\n",
    "index=2\n",
    "print(documents.raw_abstract_words[index])\n",
    "print(documents.raw_title_words[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents.raw_author_keywords[index])\n",
    "print(documents.raw_index_keywords[index])\n",
    "print(documents.title[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents.raw_index_keywords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff8a4715c70c0e4b3cc8412ea892d5df3eeb381ac1fbe083ff6ed76fad7df612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
